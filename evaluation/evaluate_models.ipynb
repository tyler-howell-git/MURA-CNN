{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8786585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "# Go from evaluation/ -> project root\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "from utils.mura_dataset import MURADataset\n",
    "from utils.transforms import get_train_transforms, get_val_transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56676ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples: 3197\n"
     ]
    }
   ],
   "source": [
    "#  Dataloader for TEST set\n",
    "def get_test_loader(batch_size: int = 32):\n",
    "    data_root = os.path.join(PROJECT_ROOT, \"data\", \"raw\")\n",
    "    test_csv = os.path.join(PROJECT_ROOT, \"data\", \"splits\", \"valid_labeled_studies.csv\")\n",
    "\n",
    "    test_dataset = MURADataset(\n",
    "        csv_file=test_csv,\n",
    "        transform=get_val_transforms(),\n",
    "        root_dir=data_root,\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    print(\"Test samples:\", len(test_dataset))\n",
    "    return test_loader\n",
    "\n",
    "test_loader = get_test_loader(batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b08d0891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline CNN definition (same as Su's training code)\n",
    "class BaselineCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        # 224x224 -> pool -> 112x112 -> pool -> 56x56, 32 channels\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))  # [B, 16, 112, 112]\n",
    "        x = self.pool(torch.relu(self.conv2(x)))  # [B, 32, 56, 56]\n",
    "        x = x.view(x.size(0), -1)                 # flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return torch.sigmoid(self.fc2(x))         # prob in [0, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d13a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and helper to evaluate one model on the test set\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "import torch\n",
    "\n",
    "# Paths to histories and weights (adjust names if needed)\n",
    "BASELINE_WEIGHTS_PATH = os.path.join(PROJECT_ROOT, \"models/baseline_cnn.pt\")\n",
    "BASELINE_HISTORY_PATH = os.path.join(PROJECT_ROOT, \"evaluation/baseline_history.npz\")\n",
    "\n",
    "MODEL10_WEIGHTS_PATH = os.path.join(PROJECT_ROOT, \"models/model1_10ep.pt\")\n",
    "MODEL10_HISTORY_PATH = os.path.join(PROJECT_ROOT, \"evaluation/model1_10ep_history.npz\")\n",
    "\n",
    "\n",
    "def load_history(path):\n",
    "    \"\"\"Load a .npz training history file.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"History file not found: {path}\")\n",
    "    h = np.load(path)\n",
    "    return {\n",
    "        \"train_loss\": h[\"train_loss\"],\n",
    "        \"val_acc\":   h[\"val_acc\"],\n",
    "        \"val_auc\":   h[\"val_auc\"],\n",
    "        \"test_acc_hist\": float(h[\"test_acc\"]),\n",
    "        \"test_auc_hist\": float(h[\"test_auc\"]),\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_checkpoint(label, weights_path, history_path, batch_size=32):\n",
    "    \"\"\"\n",
    "    Load weights + history for one model, run on the test set,\n",
    "    and compute metrics + ROC + confusion matrix.\n",
    "    \"\"\"\n",
    "    print(f\"\\n===== Evaluating {label} =====\")\n",
    "    print(f\"  Weights: {weights_path}\")\n",
    "    print(f\"  History: {history_path}\")\n",
    "\n",
    "    #load training history\n",
    "    hist = load_history(history_path)\n",
    "\n",
    "    #build DataLoader for test set\n",
    "    test_loader = get_test_loader(batch_size=batch_size)\n",
    "\n",
    "    #build model & load weights\n",
    "    model = BaselineCNN().to(device)\n",
    "    state = torch.load(weights_path, map_location=device)\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "\n",
    "    #forward pass on test set\n",
    "    all_labels = []\n",
    "    all_probs  = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            probs = model(images).cpu().numpy().flatten()   # predicted probabilities\n",
    "            all_probs.extend(probs)\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs  = np.array(all_probs)\n",
    "\n",
    "    # Binary predictions with 0.5 threshold\n",
    "    y_pred = (all_probs >= 0.5).astype(int)\n",
    "\n",
    "    #metrics\n",
    "    acc = accuracy_score(all_labels, y_pred)\n",
    "    prec = precision_score(all_labels, y_pred)\n",
    "    rec = recall_score(all_labels, y_pred)\n",
    "    f1 = f1_score(all_labels, y_pred)\n",
    "    auc_val = roc_auc_score(all_labels, all_probs)\n",
    "    fpr, tpr, thr = roc_curve(all_labels, all_probs)\n",
    "    cm = confusion_matrix(all_labels, y_pred)\n",
    "    report = classification_report(all_labels, y_pred, target_names=[\"Normal (0)\", \"Abnormal (1)\"])\n",
    "\n",
    "    print(f\"Test Accuracy (from history):   {hist['test_acc_hist']:.4f}\")\n",
    "    print(f\"Test AUC (from history):        {hist['test_auc_hist']:.4f}\")\n",
    "    print(\"--- Recomputed on test set ---\")\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1-score:  {f1:.4f}\")\n",
    "    print(f\"ROC AUC:   {auc_val:.4f}\")\n",
    "    print(\"\\nConfusion matrix:\\n\", cm)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"hist\": hist,\n",
    "        \"test_acc\": acc,\n",
    "        \"test_prec\": prec,\n",
    "        \"test_rec\": rec,\n",
    "        \"test_f1\": f1,\n",
    "        \"test_auc\": auc_val,\n",
    "        \"cm\": cm,\n",
    "        \"roc_fpr\": fpr,\n",
    "        \"roc_tpr\": tpr,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55f637b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Evaluating Baseline CNN (5 epochs) =====\n",
      "  Weights: c:\\Users\\ENOPARA\\code\\MachineLearning2025Project\\cnnradiographproject-n\\models\\baseline_cnn.pt\n",
      "  History: c:\\Users\\ENOPARA\\code\\MachineLearning2025Project\\cnnradiographproject-n\\evaluation\\baseline_history.npz\n",
      "Test samples: 3197\n",
      "Test Accuracy (from history):   0.5962\n",
      "Test AUC (from history):        0.6679\n",
      "--- Recomputed on test set ---\n",
      "Accuracy:  0.5962\n",
      "Precision: 0.7057\n",
      "Recall:    0.2680\n",
      "F1-score:  0.3884\n",
      "ROC AUC:   0.6679\n",
      "\n",
      "Confusion matrix:\n",
      " [[1496  171]\n",
      " [1120  410]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Normal (0)       0.57      0.90      0.70      1667\n",
      "Abnormal (1)       0.71      0.27      0.39      1530\n",
      "\n",
      "    accuracy                           0.60      3197\n",
      "   macro avg       0.64      0.58      0.54      3197\n",
      "weighted avg       0.64      0.60      0.55      3197\n",
      "\n",
      "\n",
      "===== Evaluating Deeper CNN (10 epochs) =====\n",
      "  Weights: c:\\Users\\ENOPARA\\code\\MachineLearning2025Project\\cnnradiographproject-n\\models\\model1_10ep.pt\n",
      "  History: c:\\Users\\ENOPARA\\code\\MachineLearning2025Project\\cnnradiographproject-n\\models\\evaluation\\model1_10ep_history.npz\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "History file not found: c:\\Users\\ENOPARA\\code\\MachineLearning2025Project\\cnnradiographproject-n\\models\\evaluation\\model1_10ep_history.npz",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#evaluation for baseline (5 ep) and 10-epoch model\u001b[39;00m\n\u001b[0;32m      3\u001b[0m baseline_results \u001b[38;5;241m=\u001b[39m evaluate_checkpoint(\n\u001b[0;32m      4\u001b[0m     label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline CNN (5 epochs)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     weights_path\u001b[38;5;241m=\u001b[39mBASELINE_WEIGHTS_PATH,\n\u001b[0;32m      6\u001b[0m     history_path\u001b[38;5;241m=\u001b[39mBASELINE_HISTORY_PATH,\n\u001b[0;32m      7\u001b[0m )\n\u001b[1;32m----> 9\u001b[0m model10_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDeeper CNN (10 epochs)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL10_WEIGHTS_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL10_HISTORY_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 49\u001b[0m, in \u001b[0;36mevaluate_checkpoint\u001b[1;34m(label, weights_path, history_path, batch_size)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  History: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhistory_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m#load training history\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mload_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m#build DataLoader for test set\u001b[39;00m\n\u001b[0;32m     52\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m get_test_loader(batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n",
      "Cell \u001b[1;32mIn[4], line 28\u001b[0m, in \u001b[0;36mload_history\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a .npz training history file.\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(path):\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHistory file not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m h \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(path)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: h[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m:   h[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_auc_hist\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(h[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_auc\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m     36\u001b[0m }\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: History file not found: c:\\Users\\ENOPARA\\code\\MachineLearning2025Project\\cnnradiographproject-n\\models\\evaluation\\model1_10ep_history.npz"
     ]
    }
   ],
   "source": [
    "#evaluation for baseline (5 ep) and 10-epoch model\n",
    "\n",
    "baseline_results = evaluate_checkpoint(\n",
    "    label=\"Baseline CNN (5 epochs)\",\n",
    "    weights_path=BASELINE_WEIGHTS_PATH,\n",
    "    history_path=BASELINE_HISTORY_PATH,\n",
    ")\n",
    "\n",
    "model10_results = evaluate_checkpoint(\n",
    "    label=\"Deeper CNN (10 epochs)\",\n",
    "    weights_path=MODEL10_WEIGHTS_PATH,\n",
    "    history_path=MODEL10_HISTORY_PATH,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mura-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
